{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b2a7bc-7daa-403a-828f-c06b012c1ae0",
   "metadata": {},
   "source": [
    "# Examples of all decoders (except Kalman Filter and Naive Bayes)\n",
    "\n",
    "In this example notebook, we:\n",
    "1. Import the necessary packages\n",
    "2. Load a data file (spike trains and outputs we are predicting)\n",
    "3. Preprocess the data for use in all decoders\n",
    "4. Run all decoders and print the goodness of fit\n",
    "5. Plot example decoded outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114ae36-f3d3-4412-b88a-9ee38ef9ef5c",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "Below, we import both standard packages, and functions from the accompanying .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b00faeb6-bf67-4091-ae7b-eb50a9715bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy import io, stats\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch import optim\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from Neural_Decoding.nn import FNN, GRU, LSTM, RNN\n",
    "from Neural_Decoding.nonlinear import WienerCascade\n",
    "from Neural_Decoding.preprocessing_funcs import LagMat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0928-9984-432b-ac08-11eb223f76d7",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "The data for this example can be downloaded at this [link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AACPWjxDKPEzQiXKUUFriFkJa?dl=0&preview=example_data_s1.pickle). It was recorded by Raeed Chowdhury from Lee Miller's lab at Northwestern.\n",
    "\n",
    "\n",
    "The data that we load is in the format described below. We have another example notebook, \"Example_format_data\", that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ce6d63-f37d-49a9-abce-a7af9e4af707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder='' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "folder = \"Decoding_data\"\n",
    "\n",
    "with open(os.path.join(folder, \"example_data_s1.pickle\"), \"rb\") as f:\n",
    "    neural_data, vels_binned = pickle.load(f, encoding=\"latin1\")  # If using python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5a06f-61c3-41e6-bbe1-0b72aa63e688",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e560cc9-d895-46fe-912e-38d5d351e0a3",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2903444-0c7d-420f-af4d-538c741ce6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_BEFORE = 6  # How many bins of neural data prior to the output are used for decoding\n",
    "BIN_CURRENT = 1  # Whether to use concurrent time bin of neural data\n",
    "BIN_AFTER = 6  # How many bins of neural data after the output are used for decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9f8af-21cf-46e6-8a1e-c6c58cb71bf6",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82d1eca-97ac-4023-aab0-be777cc50dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set decoding input\n",
    "X = neural_data.astype(\"float32\")  # torch requires float32\n",
    "\n",
    "# Set decoding output\n",
    "y = vels_binned.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4505d-859b-4d78-9da0-125ba7938909",
   "metadata": {},
   "source": [
    "### 3C. Split into training / testing / validation sets\n",
    "Note that hyperparameters should be determined using a separate validation set. \n",
    "Then, the goodness of fit should be be tested on a testing set (separate from the training and validation sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ed575-d867-4b98-be23-bb255f6aaff2",
   "metadata": {},
   "source": [
    "#### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36298c76-ef96-4b2e-9477-255d6bc7689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90cfd43-b44d-4773-a81d-47e78d14ee56",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1bf3f0-2719-4309-9194-925e17f7eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation data\n",
    "X_train_test, X_val = train_test_split(X, test_size=VAL_SIZE, shuffle=False)\n",
    "y_train_test, y_val = train_test_split(y, test_size=VAL_SIZE, shuffle=False)\n",
    "\n",
    "# Get training and test data\n",
    "X_train, X_test = train_test_split(\n",
    "    X_train_test, train_size=TRAIN_SIZE / (TRAIN_SIZE + TEST_SIZE), shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(\n",
    "    y_train_test, train_size=TRAIN_SIZE / (TRAIN_SIZE + TEST_SIZE), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946908f2-2f4c-41b3-8ece-f2303acafd1f",
   "metadata": {},
   "source": [
    "## 4. Run Decoders\n",
    "Note that in this example, we are evaluating the model fit on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cc588-1fad-460e-b521-7ec96b1f3e40",
   "metadata": {},
   "source": [
    "### 4A. Wiener Filter (Linear Regression)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e2bf201-7163-4b88-b7e6-3b1f1bd9eff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.7243494 0.7159852]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"lagmat\",\n",
    "            LagMat(\n",
    "                bin_before=BIN_BEFORE,\n",
    "                bin_current=BIN_CURRENT,\n",
    "                bin_after=BIN_AFTER,\n",
    "                flat=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\"linear\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_wf = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3a247-ebae-4d73-ab79-04226f0e742a",
   "metadata": {},
   "source": [
    "### 4B. Wiener Cascade (Linear Nonlinear Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8932e6ff-b0ba-4261-a2dd-4a80cf01b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.73109653 0.73250392]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"lagmat\",\n",
    "            LagMat(\n",
    "                bin_before=BIN_BEFORE,\n",
    "                bin_current=BIN_CURRENT,\n",
    "                bin_after=BIN_AFTER,\n",
    "                flat=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\"wc\", MultiOutputRegressor(WienerCascade(degree=3))),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_wc = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b092d-d790-443d-9b54-24e6a5bd36bb",
   "metadata": {},
   "source": [
    "### 4C. XGBoost (Extreme Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c37ba5a-5f86-4ff2-8694-3e5ad667f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.75399697 0.76834154]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"lagmat\",\n",
    "            LagMat(\n",
    "                bin_before=BIN_BEFORE,\n",
    "                bin_current=BIN_CURRENT,\n",
    "                bin_after=BIN_AFTER,\n",
    "                flat=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\"xgb\", XGBRegressor(max_depth=3, n_estimators=200, learning_rate=0.3)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_xgb = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549fb3c-094d-4f26-942f-a05e34254026",
   "metadata": {},
   "source": [
    "### 4D. SVR (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f5f8c83-22e3-41cb-938b-f5b28b68fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/laur/personal/woot/mambaforge/envs/neural_decoding/lib/python3.14/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=4000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/gpfs/laur/personal/woot/mambaforge/envs/neural_decoding/lib/python3.14/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=4000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.8152633  0.82521187]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "# The SVR works much better when the y values are normalized, so we first z-score the y values\n",
    "# We use TransformedTargetRegressor to do that.\n",
    "pipe = TransformedTargetRegressor(\n",
    "    regressor=Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\n",
    "                \"lagmat\",\n",
    "                LagMat(\n",
    "                    bin_before=BIN_BEFORE,\n",
    "                    bin_current=BIN_CURRENT,\n",
    "                    bin_after=BIN_AFTER,\n",
    "                    flat=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"svr\", MultiOutputRegressor(SVR(max_iter=4000, C=5))),\n",
    "        ]\n",
    "    ),\n",
    "    transformer=StandardScaler(),\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_svr = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f1599-100f-4cc8-a323-ed8b5ab3d39d",
   "metadata": {},
   "source": [
    "### 4E. Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "144e9f84-b549-47d1-b65e-783d2d128044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.84426105 0.8625548 ]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"lagmat\",\n",
    "            LagMat(\n",
    "                bin_before=BIN_BEFORE,\n",
    "                bin_current=BIN_CURRENT,\n",
    "                bin_after=BIN_AFTER,\n",
    "                flat=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"fnn\",\n",
    "            NeuralNetRegressor(\n",
    "                module=FNN,\n",
    "                lr=0.001,\n",
    "                iterator_train__shuffle=True,\n",
    "                optimizer=optim.Adam,\n",
    "                batch_size=32,\n",
    "                module__n_targets=y_train.shape[1],\n",
    "                module__num_units=400,\n",
    "                module__frac_dropout=0.25,\n",
    "                module__n_layers=2,\n",
    "                max_epochs=10,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_dnn = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867672fd-8dbd-4c9a-9377-84d4b937db97",
   "metadata": {},
   "source": [
    "### 4F. Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3bdbb41-54d5-441f-8128-1b166a92a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.7475089  0.72976804]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"lagmat\",\n",
    "            LagMat(\n",
    "                bin_before=BIN_BEFORE,\n",
    "                bin_current=BIN_CURRENT,\n",
    "                bin_after=BIN_AFTER,\n",
    "                flat=False,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"rnn\",\n",
    "            NeuralNetRegressor(\n",
    "                module=RNN,\n",
    "                lr=0.001,\n",
    "                iterator_train__shuffle=True,\n",
    "                optimizer=optim.RMSprop,\n",
    "                batch_size=32,\n",
    "                module__n_targets=y_train.shape[1],\n",
    "                module__num_units=400,\n",
    "                module__frac_dropout=0,\n",
    "                max_epochs=10,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_rnn = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f400e-9035-4389-b5b0-4c89319f6191",
   "metadata": {},
   "source": [
    "### 4G. GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "062ef79f-64f9-4666-b777-06eca4a3116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.7291446  0.71711385]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lagmat\", LagMat(bin_before=6, bin_current=1, bin_after=6, flat=False)),\n",
    "        (\n",
    "            \"gru\",\n",
    "            NeuralNetRegressor(\n",
    "                module=GRU,\n",
    "                lr=0.001,\n",
    "                iterator_train__shuffle=True,\n",
    "                optimizer=optim.RMSprop,\n",
    "                batch_size=32,\n",
    "                module__n_targets=y_train.shape[1],\n",
    "                module__num_units=400,\n",
    "                module__frac_dropout=0,\n",
    "                max_epochs=5,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_gru = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10c663-f8a1-4a97-a36d-a2c27535e34c",
   "metadata": {},
   "source": [
    "### 4H. LSTM (Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17df99cd-c94e-4630-9a56-202af24ec6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s: [0.75541097 0.7309768 ]\n"
     ]
    }
   ],
   "source": [
    "# Declare model\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lagmat\", LagMat(bin_before=6, bin_current=1, bin_after=6, flat=False)),\n",
    "        (\n",
    "            \"lstm\",\n",
    "            NeuralNetRegressor(\n",
    "                module=LSTM,\n",
    "                lr=0.001,\n",
    "                iterator_train__shuffle=False,\n",
    "                optimizer=optim.RMSprop,\n",
    "                batch_size=32,\n",
    "                module__n_targets=y_train.shape[1],\n",
    "                module__num_units=400,\n",
    "                module__frac_dropout=0,\n",
    "                max_epochs=5,\n",
    "                verbose=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Get metric of fit\n",
    "R2s_lstm = r2_score(y_val, y_val_pred, multioutput=\"raw_values\")\n",
    "print(\"R2s:\", R2s_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
