{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc75096-98a7-46be-a8c8-ecdf40d65a27",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "Demonstration of the benefit of using the sklearn framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33061baf-886e-49e9-ba6a-f7eaac6299a6",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "Below, we import both standard packages, and functions from the accompanying .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9b089d5-9d7f-41d6-b751-2217d17df957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy import io, stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Neural_Decoding.nn import FNN\n",
    "from Neural_Decoding.preprocessing_funcs import LagMat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321a29f-5c79-434a-a5ba-78ebac49ec2e",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "The data for this example can be downloaded at this [link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AACPWjxDKPEzQiXKUUFriFkJa?dl=0&preview=example_data_s1.pickle). It was recorded by Raeed Chowdhury from Lee Miller's lab at Northwestern.\n",
    "\n",
    "\n",
    "The data that we load is in the format described below. We have another example notebook, \"Example_format_data\", that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60346bd7-f300-459b-ad99-e45fc4dded3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder='' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "folder = \"Decoding_data\"\n",
    "\n",
    "with open(os.path.join(folder, \"example_data_s1.pickle\"), \"rb\") as f:\n",
    "    neural_data, vels_binned = pickle.load(f, encoding=\"latin1\")  # If using python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f0c6e-5d33-45c4-867a-f55f53774b42",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec7dc5-c9f1-4d7a-a722-7e419e891ea0",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2ad5de-8a86-43a1-8a00-2c4848cf4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_BEFORE = 6  # How many bins of neural data prior to the output are used for decoding\n",
    "BIN_CURRENT = 1  # Whether to use concurrent time bin of neural data\n",
    "BIN_AFTER = 6  # How many bins of neural data after the output are used for decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b614b-36b6-4955-a9a2-4d7eda5a44f3",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba19be57-eeac-4f89-a3fb-3d30917fae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set decoding input\n",
    "X = neural_data.astype(\"float32\")  # torch requires float32\n",
    "\n",
    "# Set decoding output\n",
    "y = vels_binned.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba055b3-30c7-415c-a6cb-18f88ea795be",
   "metadata": {},
   "source": [
    "## 4. Run cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944ba16-8018-4709-82c9-dcae7a245804",
   "metadata": {},
   "source": [
    "#### User Options\n",
    "\n",
    "KFold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc5bbd1-14cb-4d43-9ba5-c0c5f63ae893",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19de3ffb-883e-4761-af59-58233dceaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/2 [00:00<?, ?it/s][Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      " 50%|██████████████████████████████████████████▌                                          | 1/2 [00:01<00:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s WF: [0.73822659 0.7493962  0.71846437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   42.8s finished\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:44<00:00, 22.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2s FNN: [0.83662546 0.84977973 0.83463073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"WF\": {\n",
    "        \"estimator\": Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"lagmat\", LagMat(BIN_BEFORE, BIN_CURRENT, BIN_AFTER, flat=True)),\n",
    "                (\"linear\", LinearRegression()),\n",
    "            ]\n",
    "        ),\n",
    "    },\n",
    "    \"FNN\": {\n",
    "        \"estimator\": Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"lagmat\", LagMat(BIN_BEFORE, BIN_CURRENT, BIN_AFTER, flat=True)),\n",
    "                (\n",
    "                    \"fnn\",\n",
    "                    NeuralNetRegressor(\n",
    "                        module=FNN,\n",
    "                        lr=0.001,\n",
    "                        iterator_train__shuffle=True,\n",
    "                        optimizer=optim.Adam,\n",
    "                        batch_size=32,\n",
    "                        module__n_targets=y.shape[1],\n",
    "                        module__num_units=400,\n",
    "                        module__frac_dropout=0.25,\n",
    "                        module__n_layers=2,\n",
    "                        max_epochs=10,\n",
    "                        verbose=0,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "for name in tqdm(models):\n",
    "    model = models[name][\"estimator\"]\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=KFold(n_splits=N_SPLITS),\n",
    "        scoring=\"r2\",\n",
    "        n_jobs=1,  # parallelisation\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(f\"R2s {name}: {cv_results['test_score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
